#!/usr/bin/env python3
"""
JSON Vulnerability to CSV Converter

This script converts JSON vulnerability files to CSV format,
preserving all fields in separate columns with proper flattening of nested structures.

Author: Phoenix Security Configuration System
Version: 1.1
Date: 2025
"""

import json
import pandas as pd
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Union
import argparse

def flatten_json(data: Dict[str, Any], parent_key: str = '', separator: str = '_') -> Dict[str, Any]:
    """
    Recursively flatten a nested JSON object.
    
    Args:
        data: Dictionary to flatten
        parent_key: Parent key for nested items
        separator: Separator for nested keys
    
    Returns:
        Flattened dictionary
    """
    items = []
    
    for key, value in data.items():
        new_key = f"{parent_key}{separator}{key}" if parent_key else key
        
        if isinstance(value, dict):
            # Recursively flatten nested dictionaries
            items.extend(flatten_json(value, new_key, separator).items())
        elif isinstance(value, list):
            # Handle lists
            if not value:  # Empty list
                items.append((new_key, ''))
            elif all(isinstance(item, dict) for item in value):
                # List of dictionaries - create separate columns for each dict item
                for i, item in enumerate(value):
                    flattened_item = flatten_json(item, f"{new_key}_{i}", separator)
                    items.extend(flattened_item.items())
            elif all(isinstance(item, str) for item in value):
                # List of strings - join with semicolon
                items.append((new_key, '; '.join(value)))
            else:
                # Mixed list - convert to string representation
                items.append((new_key, str(value)))
        else:
            # Simple value
            items.append((new_key, value))
    
    return dict(items)

def process_vulnerability_json(file_path: str) -> tuple[pd.DataFrame, dict]:
    """
    Process a JSON vulnerability file and convert to DataFrame.
    
    Args:
        file_path: Path to the JSON file
    
    Returns:
        Tuple of (pandas DataFrame with flattened vulnerability data, metadata dict)
    """
    print(f"üìÇ Loading JSON file: {file_path}")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read().strip()
            
        # Try to parse as single JSON first
        try:
            data = json.loads(content)
        except json.JSONDecodeError:
            # If that fails, try to parse as multiple JSON objects
            print("üìÇ Single JSON parsing failed, trying multiple JSON objects...")
            json_objects = []
            
            # Split by lines and try to parse each as JSON
            lines = content.split('\n')
            current_json = ""
            brace_count = 0
            
            for line in lines:
                current_json += line
                # Count braces to detect complete JSON objects
                brace_count += line.count('{') - line.count('}')
                
                if brace_count == 0 and current_json.strip():
                    try:
                        obj = json.loads(current_json)
                        json_objects.append(obj)
                        current_json = ""
                    except json.JSONDecodeError:
                        # Continue building the JSON string
                        current_json += "\n"
            
            if not json_objects:
                print(f"‚ùå Error: Could not parse any valid JSON objects from {file_path}")
                return pd.DataFrame(), {}
            
            print(f"üìä Found {len(json_objects)} JSON objects in file")
            
            # Combine all content arrays from multiple JSON objects
            all_vulnerabilities = []
            combined_metadata = {}
            
            for i, obj in enumerate(json_objects):
                if 'content' in obj and isinstance(obj['content'], list):
                    all_vulnerabilities.extend(obj['content'])
                    # Use metadata from the last object (most recent)
                    for key in ['totalElements', 'totalPages', 'number', 'size', 'numberOfElements']:
                        if key in obj:
                            combined_metadata[key] = obj[key]
            
            if not all_vulnerabilities:
                print(f"‚ùå Error: No vulnerability content found in any JSON object")
                return pd.DataFrame(), {}
            
            # Create a combined data structure
            data = {
                'content': all_vulnerabilities,
                **combined_metadata
            }
            
            print(f"üìä Combined {len(all_vulnerabilities)} vulnerabilities from {len(json_objects)} JSON objects")
            
    except json.JSONDecodeError as e:
        print(f"‚ùå Error: Invalid JSON format in {file_path}")
        print(f"   Details: {e}")
        return pd.DataFrame(), {}
    except FileNotFoundError:
        print(f"‚ùå Error: File not found: {file_path}")
        return pd.DataFrame(), {}
    except Exception as e:
        print(f"‚ùå Error reading file {file_path}: {e}")
        return pd.DataFrame(), {}
    
    # Check if data has the expected structure
    if not isinstance(data, dict):
        print(f"‚ùå Error: JSON file is not a valid object")
        return pd.DataFrame(), {}
    
    # Handle different JSON structures and extract metadata
    vulnerabilities = None
    metadata = {}
    
    if 'content' in data and isinstance(data['content'], list):
        # Standard structure with 'content' array
        vulnerabilities = data['content']
        print(f"üìä Found paginated structure with {len(vulnerabilities)} records")
        
        # Extract pagination metadata
        for key in ['totalElements', 'totalPages', 'number', 'size', 'numberOfElements']:
            if key in data:
                metadata[key] = data[key]
                if key == 'totalElements':
                    print(f"üìä Total elements in dataset: {data[key]}")
    elif isinstance(data, list):
        # Direct array of vulnerabilities
        vulnerabilities = data
        print(f"üìä Found direct array structure with {len(vulnerabilities)} records")
    else:
        print(f"‚ùå Error: JSON file does not have expected structure")
        print(f"   Expected: Object with 'content' array or direct array")
        print(f"   Found: Object with keys: {list(data.keys())}")
        return pd.DataFrame(), {}
    
    if not vulnerabilities:
        print(f"‚ùå Error: No vulnerability data found")
        return pd.DataFrame(), {}
    
    print(f"üìä Processing {len(vulnerabilities)} vulnerability records...")
    
    # Flatten each vulnerability record
    flattened_records = []
    for i, vuln in enumerate(vulnerabilities):
        try:
            flattened = flatten_json(vuln)
            flattened_records.append(flattened)
        except Exception as e:
            print(f"‚ö†Ô∏è  Warning: Error processing record {i+1}: {e}")
            continue
    
    if not flattened_records:
        print("‚ùå Error: No valid records found to process")
        return pd.DataFrame(), {}
    
    # Create DataFrame
    df = pd.DataFrame(flattened_records)
    
    # Fill NaN values with empty strings for better Excel compatibility
    df = df.fillna('')
    
    print(f"‚úÖ Successfully processed {len(df)} records with {len(df.columns)} columns")
    
    return df, metadata

def save_to_csv(df: pd.DataFrame, output_path: str, metadata: dict = None) -> bool:
    """
    Save DataFrame to CSV file with metadata summary.
    
    Args:
        df: DataFrame to save
        output_path: Output file path
        metadata: Optional metadata dictionary
    
    Returns:
        True if successful, False otherwise
    """
    try:
        print(f"üíæ Saving to CSV: {output_path}")
        
        # Save main CSV file
        df.to_csv(output_path, index=False, encoding='utf-8')
        
        # Create a summary file alongside the main CSV
        summary_path = output_path.replace('.csv', '_summary.txt')
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("JSON VULNERABILITY TO CSV CONVERSION SUMMARY\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"üìä Processing Summary:\n")
            f.write(f"   ‚Ä¢ Total Vulnerabilities: {len(df)}\n")
            f.write(f"   ‚Ä¢ Total Columns: {len(df.columns)}\n")
            f.write(f"   ‚Ä¢ Source File: {os.path.basename(output_path.replace('.csv', '.json'))}\n")
            f.write(f"   ‚Ä¢ Generation Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # Add metadata if available
            if metadata:
                f.write(f"üìã Source Metadata:\n")
                for key, value in metadata.items():
                    f.write(f"   ‚Ä¢ {key}: {value}\n")
                f.write("\n")
            
            # Column information
            f.write(f"üìë Column Information ({len(df.columns)} columns):\n")
            f.write("-" * 60 + "\n")
            
            for col in df.columns:
                non_empty_count = df[col].astype(str).str.strip().ne('').sum()
                sample_values = df[col].dropna().astype(str).str.strip()
                sample_values = sample_values[sample_values != ''].head(2).tolist()
                
                f.write(f"‚Ä¢ {col}\n")
                f.write(f"  Non-empty records: {non_empty_count}/{len(df)} ({non_empty_count/len(df)*100:.1f}%)\n")
                if sample_values:
                    f.write(f"  Sample values: {'; '.join(sample_values)}\n")
                f.write("\n")
        
        print(f"‚úÖ CSV file saved successfully: {output_path}")
        print(f"‚úÖ Summary file saved: {summary_path}")
        return True
        
    except Exception as e:
        print(f"‚ùå Error saving CSV file: {e}")
        return False

def get_column_info(df: pd.DataFrame) -> pd.DataFrame:
    """
    Generate column information summary.
    
    Args:
        df: DataFrame to analyze
    
    Returns:
        DataFrame with column information
    """
    column_info = []
    
    for col in df.columns:
        non_empty_count = df[col].astype(str).str.strip().ne('').sum()
        sample_values = df[col].dropna().astype(str).str.strip()
        sample_values = sample_values[sample_values != ''].head(3).tolist()
        
        column_info.append({
            'Column Name': col,
            'Non-Empty Count': non_empty_count,
            'Sample Values': '; '.join(sample_values) if sample_values else 'No data'
        })
    
    return pd.DataFrame(column_info)

def main():
    """Main function to handle command-line interface and file processing."""
    
    print("=" * 80)
    print("üîß JSON Vulnerability to CSV Converter")
    print("   Phoenix Security Configuration System")
    print("=" * 80)
    print()
    
    # Set up argument parser
    parser = argparse.ArgumentParser(
        description='Convert JSON vulnerability files to CSV format',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python json_to_spreadsheet_converter.py
  python json_to_spreadsheet_converter.py --input vulnerability-data.json
  python json_to_spreadsheet_converter.py --input data.json --output report.csv
        """
    )
    
    parser.add_argument(
        '--input', '-i',
        type=str,
        help='Input JSON file path (if not provided, will prompt user)'
    )
    
    parser.add_argument(
        '--output', '-o',
        type=str,
        help='Output CSV file path (if not provided, will auto-generate)'
    )
    
    parser.add_argument(
        '--show-columns',
        action='store_true',
        help='Display column information after processing'
    )
    
    args = parser.parse_args()
    
    # Get input file
    if args.input:
        input_file = args.input
    else:
        print("üìÅ Available JSON files in current directory:")
        json_files = [f for f in os.listdir('.') if f.endswith('.json')]
        
        if not json_files:
            print("   No JSON files found in current directory.")
            input_file = input("\nüîç Please enter the full path to your JSON file: ").strip()
        else:
            for i, file in enumerate(json_files, 1):
                file_size = os.path.getsize(file) / (1024 * 1024)  # Size in MB
                print(f"   {i}. {file} ({file_size:.1f} MB)")
            
            print(f"   {len(json_files) + 1}. Enter custom path")
            
            while True:
                try:
                    choice = input(f"\nüîç Select file (1-{len(json_files) + 1}): ").strip()
                    
                    if choice.isdigit():
                        choice_num = int(choice)
                        if 1 <= choice_num <= len(json_files):
                            input_file = json_files[choice_num - 1]
                            break
                        elif choice_num == len(json_files) + 1:
                            input_file = input("üîç Please enter the full path to your JSON file: ").strip()
                            break
                    
                    print("‚ùå Invalid selection. Please try again.")
                except KeyboardInterrupt:
                    print("\n\nüëã Operation cancelled by user.")
                    sys.exit(0)
    
    # Validate input file
    if not os.path.exists(input_file):
        print(f"‚ùå Error: File does not exist: {input_file}")
        sys.exit(1)
    
    # Generate output file name if not provided
    if args.output:
        output_file = args.output
    else:
        base_name = os.path.splitext(os.path.basename(input_file))[0]
        output_file = f"{base_name}_vulnerability_report.csv"
    
    print(f"\nüìã Processing Configuration:")
    print(f"   Input File:  {input_file}")
    print(f"   Output File: {output_file}")
    print()
    
    # Process the JSON file
    df, metadata = process_vulnerability_json(input_file)
    
    if df.empty:
        print("‚ùå Failed to process the JSON file. Please check the file format and try again.")
        sys.exit(1)
    
    # Show column information if requested
    if args.show_columns:
        print("\nüìä Column Information:")
        print("-" * 80)
        column_info = get_column_info(df)
        for _, row in column_info.iterrows():
            print(f"Column: {row['Column Name']}")
            print(f"  Non-empty records: {row['Non-Empty Count']}")
            print(f"  Sample values: {row['Sample Values']}")
            print()
    
    # Save to CSV
    success = save_to_csv(df, output_file, metadata)
    
    if success:
        print("\nüéâ Conversion completed successfully!")
        print(f"üìä Summary:")
        print(f"   ‚Ä¢ {len(df)} vulnerability records processed")
        print(f"   ‚Ä¢ {len(df.columns)} columns created")
        print(f"   ‚Ä¢ Output saved to: {output_file}")
        print(f"\nüí° Output files created:")
        print(f"   ‚Ä¢ Main CSV: All vulnerability records with flattened columns")
        print(f"   ‚Ä¢ Summary TXT: Processing summary, metadata, and column information")
        
        # Show some key statistics
        if not df.empty:
            print(f"\nüìà Key Statistics:")
            
            # Risk statistics
            if 'stats_risk' in df.columns:
                risk_stats = df['stats_risk'].astype(str).str.strip()
                risk_stats = risk_stats[risk_stats != ''].astype(float)
                if not risk_stats.empty:
                    print(f"   ‚Ä¢ Average Risk Score: {risk_stats.mean():.1f}")
                    print(f"   ‚Ä¢ Max Risk Score: {risk_stats.max():.0f}")
            
            # Finding types
            if 'stats_findingTypes' in df.columns:
                finding_types = df['stats_findingTypes'].astype(str).str.strip()
                finding_types = finding_types[finding_types != '']
                unique_types = set()
                for types_str in finding_types:
                    if types_str and types_str != 'nan':
                        unique_types.update(types_str.split('; '))
                if unique_types:
                    print(f"   ‚Ä¢ Finding Types: {', '.join(sorted(unique_types))}")
            
            # CVE count
            cve_columns = [col for col in df.columns if 'referenceIds' in col and 'id' in col]
            if cve_columns:
                cve_count = 0
                for col in cve_columns:
                    cve_values = df[col].astype(str).str.strip()
                    cve_count += (cve_values.str.startswith('CVE-')).sum()
                if cve_count > 0:
                    print(f"   ‚Ä¢ CVE References: {cve_count}")
    else:
        print("\n‚ùå Conversion failed. Please check the error messages above.")
        sys.exit(1)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nüëã Operation cancelled by user.")
        sys.exit(0)
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {e}")
        sys.exit(1)
